# ğŸï¸ F1 Constructor Championship Predictor

A Python application that predicts future F1 constructor championship standings using **Llama 3 8B** via Ollama with **RAG (Retrieval Augmented Generation)**.

![Python](https://img.shields.io/badge/Python-3.x-blue)
![Streamlit](https://img.shields.io/badge/Streamlit-UI-red)
![ChromaDB](https://img.shields.io/badge/ChromaDB-Vector%20Store-green)

---

## ğŸ“ Project Structure

```
F1 bot/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ constructor_standings.csv   # Historical constructor standings
â”‚   â”œâ”€â”€ constructors.csv            # Constructor names and details
â”‚   â””â”€â”€ races.csv                   # Race information (year, round)
â”œâ”€â”€ vector_db/                      # ChromaDB storage (auto-generated)
â”œâ”€â”€ data_cleaning.py                # Data loading & cleaning
â”œâ”€â”€ vector_store.py                 # Vector database management
â”œâ”€â”€ predict.py                      # LLM prediction with RAG
â”œâ”€â”€ app.py                          # Streamlit web UI
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Requirements

### Python Packages
```bash
pip install pandas requests streamlit chromadb sentence-transformers
```

### External
- **Ollama** with Llama 3 8B model installed
  ```bash
  ollama pull llama3:8b
  ```

---

## ğŸš€ How to Run

### Step 1: Build Vector Database (First time only)
```bash
cd "F1 bot"
python3 vector_store.py
```
This creates embeddings for all F1 historical data in ChromaDB (~998 documents).

### Step 2: Start Ollama
```bash
ollama serve
```

### Step 3: Run the Application

**Option A: Web UI (Recommended)**
```bash
streamlit run app.py
```
Open [http://localhost:8501](http://localhost:8501) in your browser.

**Option B: Command Line**
```bash
python3 predict.py
```

---

## ğŸ—ï¸ Architecture

This project uses **RAG (Retrieval Augmented Generation)**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   F1 CSV Data   â”‚â”€â”€â”€â”€â–¶â”‚  Sentence        â”‚â”€â”€â”€â”€â–¶â”‚   ChromaDB      â”‚
â”‚                 â”‚     â”‚  Transformers    â”‚     â”‚   Vector Store  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  (Embeddings)    â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                                                          â”‚ Semantic Search
                                                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Prediction    â”‚â—€â”€â”€â”€â”€â”‚   Llama 3 8B     â”‚â—€â”€â”€â”€â”€â”‚   Retrieved     â”‚
â”‚   Output        â”‚     â”‚   (via Ollama)   â”‚     â”‚   Context       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. Historical F1 data is embedded using `all-MiniLM-L6-v2`
2. Embeddings stored in ChromaDB vector database
3. Semantic search retrieves relevant historical context
4. Retrieved context + prompt sent to Llama 3 8B
5. LLM generates predictions based on relevant data

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ§  **RAG Predictions** | Semantic search for relevant historical context |
| ğŸ—„ï¸ **Vector Database** | ChromaDB for efficient embedding storage |
| ğŸ”„ **Mode Toggle** | Switch between RAG and legacy mode |
| ğŸ” **Custom Query** | Focus predictions on specific aspects (e.g., "Red Bull dominance") |
| ğŸ“Š **Data Visualization** | View historical standings in the UI |
| ğŸ›ï¸ **Temperature Control** | Adjust model creativity |
| ğŸ¨ **F1-Themed UI** | Clean Streamlit interface |

---

## ğŸ” Custom Query Examples

The custom query parameter focuses RAG retrieval on specific aspects:

| Query | Effect |
|-------|--------|
| `Red Bull dominance` | More context about Red Bull's championships |
| `Ferrari wins` | Focus on Ferrari's historical victories |
| `midfield battle` | Data about teams in positions 4-7 |
| `Mercedes decline` | Context about Mercedes losing ground |

---

## ğŸ“œ File Execution Order

1. **`vector_store.py`** - Build vector database (run once)
2. **`data_cleaning.py`** - Loads/cleans CSV data (imported automatically)
3. **`predict.py`** - Makes predictions using RAG + Ollama
4. **`app.py`** - Runs the Streamlit web interface

---

## ğŸ“„ License

MIT License - Feel free to use and modify!
